{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# HGNN - PPO Training\n",
    "- Model = L2DPPOModel"
   ],
   "id": "920c0e7e898d159e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from rl4co.envs.scheduling.jssp.env import JSSPEnv\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from rl4co.envs.scheduling.djssp.env import DJSSPEnv\n",
    "from rl4co.models import L2DPPOModel\n",
    "from rl4co.utils import RL4COTrainer\n",
    "\n",
    "generator_params = {\n",
    "\"num_jobs\" : 8 ,\n",
    "\"num_machines\": 8 ,\n",
    "\"min_processing_time\": 20 ,\n",
    "\"max_processing_time\": 99 ,\n",
    "\"mtbf\": 30,\n",
    "\"mttr\": 10\n",
    "}\n",
    "env = DJSSPEnv(generator_params=generator_params,\n",
    "_torchrl_mode=True,\n",
    "stepwise_reward=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "ebd0d44660c378fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Device Realted Details",
   "id": "d51da9b6b346d954"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    accelerator = \"gpu\"\n",
    "    batch_size = 256\n",
    "    train_data_size = 2_000\n",
    "    embed_dim = 128\n",
    "    num_encoder_layers = 4\n",
    "else:\n",
    "    accelerator = \"cpu\"\n",
    "    batch_size = 32\n",
    "    train_data_size = 1_000\n",
    "    embed_dim = 64\n",
    "    num_encoder_layers = 2"
   ],
   "id": "f72a2c4c451ef6d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### WandB",
   "id": "d613fdaf5e473a0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "run = wandb.init(\n",
    "    project = \"rl4co\",\n",
    "    notes = \"GNN-PPO-Training\"\n",
    ")\n",
    "\n",
    "\n",
    "logger = WandbLogger(project=\"rl4co\", name=\"GNN-PPO-Training\")"
   ],
   "id": "86fbcd4897d1a223",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model - Policy\n",
    "- het embeddings\n"
   ],
   "id": "7000c6c0fd063348"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "policy_kwargs = {\n",
    "  \"embed_dim\": 256,\n",
    "  \"num_encoder_layers\":3,\n",
    "  \"scaling_factor\": 1000,\n",
    "  \"ppo_epochs\":2,\n",
    "  \"het_emb\": True,\n",
    "  \"normalization\": \"instance\"\n",
    "}\n",
    "model = L2DPPOModel(env=env,policy_kwargs=policy_kwargs,  batch_size=128,val_batch_size=512,test_batch_size=64,mini_batch_size=512)"
   ],
   "id": "14a90585361e05d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Scheduling of the untrained model",
   "id": "c757b3be973e1bb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "td_init = env.reset(batch_size=[1])\n",
    "# we must send td to device otherwise it throws an error\n",
    "td_init = td_init.to(device)"
   ],
   "id": "f571c88ccd38ffd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# same for the policy\n",
    "policy = model.policy.to(device=device)"
   ],
   "id": "e53e9218396b7e94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Greedy",
   "id": "6d881a963e9fb822"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "out_untrained_greedy = policy(td_init.clone(), env, phase=\"test\", decode_type=\"greedy\")\n",
    "\n",
    "print(\"Untrained greedy output with the makespan \", out_untrained_greedy[\"reward\"][0])\n",
    "\n",
    "# for multiple batches use this:\n",
    "# print(f\"Greedy - Rewards: {[f'{-r.item():.2f}' for r in out_untrained_greedy['reward']]}\")\n"
   ],
   "id": "326504863a21bed8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# render the output of the untrained greedy\n",
    "env.render(out_untrained_greedy[\"td\"] , 0)"
   ],
   "id": "5d6e66f8913a6415",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MultistartSampling",
   "id": "94cc3e81a5b61d58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T00:16:09.730929Z",
     "start_time": "2025-01-04T00:15:58.364153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_untrained_multistart = policy.generate(td_init.clone(), env=env, phase=\"test\", decode_type=\"multistart_sampling\", num_starts=100, select_best=True)\n",
    "print(f\"Untrained Multistart - Makespan: {[f'{-r.item():.2f}' for r in out_untrained_multistart['reward']]}\")"
   ],
   "id": "7535b7c52e0c4c67",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soner\\anaconda3\\envs\\reinforce\\Lib\\site-packages\\executing\\executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "C:\\Users\\soner\\anaconda3\\envs\\reinforce\\Lib\\ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m out_untrained_multistart \u001B[38;5;241m=\u001B[39m policy\u001B[38;5;241m.\u001B[39mgenerate(td_init\u001B[38;5;241m.\u001B[39mclone(), env\u001B[38;5;241m=\u001B[39menv, phase\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, decode_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultistart_sampling\u001B[39m\u001B[38;5;124m\"\u001B[39m, num_starts\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, select_best\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUntrained Multistart - Makespan: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m-\u001B[39mr\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mr\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mout_untrained_multistart[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreward\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\reinforce\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\models\\zoo\\l2d\\policy.py:250\u001B[0m, in \u001B[0;36mgenerate\u001B[1;34m(self, td, env, phase, **kwargs)\u001B[0m\n\u001B[0;32m    245\u001B[0m     td[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maction\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m action_indexes\n\u001B[0;32m    247\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m td\n\u001B[0;32m    249\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mno_grad()\n\u001B[1;32m--> 250\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate\u001B[39m(\u001B[38;5;28mself\u001B[39m, td, env\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, phase: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m:\n\u001B[0;32m    251\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m phase \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdont use generate() in training mode\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    252\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\reinforce\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\reinforce\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\models\\common\\constructive\\base.py:240\u001B[0m, in \u001B[0;36mConstructivePolicy.forward\u001B[1;34m(self, td, env, phase, calc_reward, return_actions, return_entropy, return_hidden, return_init_embeds, return_sum_log_likelihood, actions, max_steps, **decoding_kwargs)\u001B[0m\n\u001B[0;32m    231\u001B[0m logits, mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(td, hidden, num_starts)\n\u001B[0;32m    234\u001B[0m td \u001B[38;5;241m=\u001B[39m decode_strategy\u001B[38;5;241m.\u001B[39mstep(\n\u001B[0;32m    235\u001B[0m     logits,\n\u001B[0;32m    236\u001B[0m     mask,\n\u001B[0;32m    237\u001B[0m     td,\n\u001B[0;32m    238\u001B[0m     action\u001B[38;5;241m=\u001B[39mactions[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, step] \u001B[38;5;28;01mif\u001B[39;00m actions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    239\u001B[0m )\n\u001B[1;32m--> 240\u001B[0m td \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(td)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnext\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    241\u001B[0m step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m step \u001B[38;5;241m>\u001B[39m max_steps:\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\envs\\common\\base.py:133\u001B[0m, in \u001B[0;36mRL4COEnvBase.step\u001B[1;34m(self, td)\u001B[0m\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnext\u001B[39m\u001B[38;5;124m\"\u001B[39m: td}\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    132\u001B[0m     \u001B[38;5;66;03m# Since we simplify the syntax\u001B[39;00m\n\u001B[1;32m--> 133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_torchrl_step(td)\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\envs\\common\\base.py:157\u001B[0m, in \u001B[0;36mRL4COEnvBase._torchrl_step\u001B[1;34m(self, td)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assert_tensordict_shape(td)\n\u001B[0;32m    155\u001B[0m next_preset \u001B[38;5;241m=\u001B[39m td\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnext\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m--> 157\u001B[0m next_tensordict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_step(\n\u001B[0;32m    158\u001B[0m     td\u001B[38;5;241m.\u001B[39mclone()\n\u001B[0;32m    159\u001B[0m )  \u001B[38;5;66;03m# NOTE: we clone to avoid recursion error\u001B[39;00m\n\u001B[0;32m    160\u001B[0m next_tensordict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_step_proc_data(next_tensordict)\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m next_preset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\envs\\scheduling\\djssp\\env.py:313\u001B[0m, in \u001B[0;36mDJSSPEnv._step\u001B[1;34m(self, td)\u001B[0m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m step_complete\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m    312\u001B[0m     td, dones \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transit_to_next_time(step_complete, td)\n\u001B[1;32m--> 313\u001B[0m     td\u001B[38;5;241m.\u001B[39mset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maction_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_action_mask(td))\n\u001B[0;32m    314\u001B[0m     step_complete \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_step_complete(td, dones)\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_mask:\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\envs\\scheduling\\djssp\\env.py:244\u001B[0m, in \u001B[0;36mDJSSPEnv.get_action_mask\u001B[1;34m(self, td)\u001B[0m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_action_mask\u001B[39m(\u001B[38;5;28mself\u001B[39m, td: TensorDict) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 244\u001B[0m     action_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_job_machine_availability(td)\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmask_no_ops:\n\u001B[0;32m    246\u001B[0m         \u001B[38;5;66;03m# masking is only allowed if instance is finished\u001B[39;00m\n\u001B[0;32m    247\u001B[0m         no_op_mask \u001B[38;5;241m=\u001B[39m td[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdone\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\envs\\scheduling\\djssp\\env.py:609\u001B[0m, in \u001B[0;36mDJSSPEnv._get_job_machine_availability\u001B[1;34m(self, td)\u001B[0m\n\u001B[0;32m    607\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m td\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    608\u001B[0m \u001B[38;5;66;03m# TODO: CHECK_MACHINE_BREAKDOWNS_GET_JOB_MACHINE_AVAILABILITY\u001B[39;00m\n\u001B[1;32m--> 609\u001B[0m td \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_machine_breakdowns(td)\n\u001B[0;32m    611\u001B[0m \u001B[38;5;66;03m# (bs, jobs, machines)\u001B[39;00m\n\u001B[0;32m    612\u001B[0m action_mask \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfull((batch_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_jobs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_mas), \u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m    613\u001B[0m     td\u001B[38;5;241m.\u001B[39mdevice\n\u001B[0;32m    614\u001B[0m )\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\envs\\scheduling\\djssp\\env.py:210\u001B[0m, in \u001B[0;36mDJSSPEnv._check_machine_breakdowns\u001B[1;34m(self, td)\u001B[0m\n\u001B[0;32m    204\u001B[0m machine_idx_breakdowns \u001B[38;5;241m=\u001B[39m machine_breakdowns[batch_id,machine_idx]\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m breakdown_no \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mint\u001B[39m(machine_breakdowns\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m)):\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;66;03m# 0-2-4-6-8...-> breakdown occurence time\u001B[39;00m\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;66;03m# 1-3-5-7-9...-> breakdown duration\u001B[39;00m\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;66;03m# if current time == machine breakdown time\u001B[39;00m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;66;03m# if machine_idx_breakdowns[breakdown_no][\"TIME\"] == td[\"time\"][batch_id]:\u001B[39;00m\n\u001B[1;32m--> 210\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m machine_idx_breakdowns[(breakdown_no)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m==\u001B[39m td[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m\"\u001B[39m][batch_id]:\n\u001B[0;32m    211\u001B[0m         \u001B[38;5;66;03m# duration of the breakdown\u001B[39;00m\n\u001B[0;32m    212\u001B[0m         duration \u001B[38;5;241m=\u001B[39m machine_idx_breakdowns[(breakdown_no)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m ]\n\u001B[0;32m    213\u001B[0m         \u001B[38;5;66;03m# machine is busy(not available) until -> \" current_time + duration of the breakdown\"\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "env.render(out_untrained_multistart[\"td\"] , 0)",
   "id": "662780bb2c831796",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training the Model",
   "id": "7350b97ea72187f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checkpoint - Callback Setup",
   "id": "e1e902c8695e5c3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint, RichModelSummary\n",
    "\n",
    "# Checkpointing callback: save models when validation reward improves\n",
    "checkpoint_callback = ModelCheckpoint(  dirpath=\"checkpoints\", # save to checkpoints/\n",
    "                                        filename=\"epoch_{epoch:03d}\",  # save as epoch_XXX.ckpt\n",
    "                                        save_top_k=1, # save only the best model\n",
    "                                        save_last=True, # save the last model\n",
    "                                        monitor=\"val/reward\", # monitor validation reward\n",
    "                                        mode=\"max\") # maximize validation reward\n",
    "# Print model summary\n",
    "rich_model_summary = RichModelSummary(max_depth=3)\n",
    "\n",
    "# Callbacks list\n",
    "callbacks = [checkpoint_callback, rich_model_summary]\n",
    "\n"
   ],
   "id": "72a1515575f30408",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training\n",
   "id": "c380d5d2205c6c74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#CHECKPOINT_PATH = \"last.ckpt\"\n",
    "CHECKPOINT_PATH = \"checkpoints/last.ckpt\"\n",
    "try:\n",
    "    model = L2DPPOModel.load_from_checkpoint(CHECKPOINT_PATH)\n",
    "except FileNotFoundError:\n",
    "\n",
    "    # max_epochs = 10\n",
    "    trainer = RL4COTrainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=accelerator,\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    trainer.fit(model)\n",
    "finally:\n",
    "    model = model.to(device)\n"
   ],
   "id": "3073c86f2b1d35b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Scheduling of the Trained Model",
   "id": "23d8f4950b7262f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "td_init = td_init.to(device)\n",
    "# same for the policy\n",
    "policy = model.policy.to(device=device)"
   ],
   "id": "e034be24deb8c1aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Greedy",
   "id": "4e732e2970f90a86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "out_trained_greedy = policy(td_init.clone(), env, phase=\"test\", decode_type=\"greedy\")\n",
    "\n",
    "print(\"Trained greedy output with the makespan \", out_trained_greedy[\"reward\"][0])"
   ],
   "id": "8b2305af4e42cbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "env.render(out_trained_greedy[\"td\"] , 0)",
   "id": "6bc6258be4e075c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Multistart",
   "id": "39b7d91e62f957c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "out_trained_multistart = policy.generate(td_init.clone(), env=env, phase=\"test\", decode_type=\"multistart_sampling\", num_starts=100, select_best=True)\n",
    "print(f\"Trained Multistart - Rewards: {[f'{-r.item():.2f}' for r in out_trained_multistart['reward']]}\")"
   ],
   "id": "cae4fbbc0fce93d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "env.render(out_trained_multistart[\"td\"] , 0)\n",
   "id": "e98c28bfc7c09947",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test on Taillard Benchmark",
   "id": "f508f520e413a412"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "! git clone https://github.com/tamy0612/JSPLIB.git",
   "id": "f711373b80a8f08e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def prepare_taillard_data(nj, nm):\n",
    "    # Target folder for Taillard instances\n",
    "    fp = f\"taillard/{nj}x{nm}\"\n",
    "\n",
    "    if not os.path.exists(fp):\n",
    "        os.makedirs(fp)\n",
    "\n",
    "    # Load the JSON file\n",
    "    with open('JSPLIB/instances.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Filter Taillard instances with matching jobs and machines\n",
    "    instances = [x for x in data if \"ta\" in x[\"name\"] and x[\"jobs\"] == nj and x[\"machines\"] == nm]\n",
    "    print(f\"Found {len(instances)} instances for {nj} jobs and {nm} machines\")\n",
    "\n",
    "    if not instances:\n",
    "        raise FileNotFoundError(f\"No matching Taillard instances found for {nj}x{nm}\")\n",
    "\n",
    "    # Copy files and validate\n",
    "    for instance in instances:\n",
    "        source_path = os.path.join(\"JSPLIB\", instance['path'])\n",
    "        target_path = os.path.join(fp, f\"{instance['name']}.txt\")\n",
    "\n",
    "        # Check if the source file exists\n",
    "        if os.path.exists(source_path):\n",
    "            print(f\"Copying {source_path} to {target_path}\")\n",
    "            os.system(f\"cp {source_path} {target_path}\")\n",
    "        else:\n",
    "            print(f\"Warning: Source file {source_path} does not exist\")\n",
    "\n",
    "    # Verify if files were copied\n",
    "    files_in_target = os.listdir(fp)\n",
    "    assert len(files_in_target) > 0, f\"No files copied to {fp}. Check source paths.\"\n",
    "    print(f\"Successfully prepared {len(files_in_target)} files in {fp}\")"
   ],
   "id": "92f799096ab5b965",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# path to taillard instances\n",
    "FILE_PATH = \"taillard/{nj}x{nm}\"\n",
    "\n",
    "results = {}\n",
    "instance_types = [(15, 15), (20, 15), (20, 20), (30, 15), (30, 20)]\n",
    "\n",
    "for instance_type in instance_types:\n",
    "    print(\"------------\")\n",
    "    nj, nm = instance_type\n",
    "    prepare_taillard_data(nj, nm)\n",
    "    dataset = env.dataset(batch_size=[10], phase=\"test\", filename=FILE_PATH.format(nj=nj, nm=nm))\n",
    "    dl = DataLoader(dataset, batch_size=5, collate_fn=dataset.collate_fn)\n",
    "    rewards = []\n",
    "\n",
    "    for batch in dl:\n",
    "        td = env.reset(batch).to(device)\n",
    "        # use policy.generate to avoid grad calculations which can lead to oom\n",
    "        out = model.policy.generate(td, env=env, phase=\"test\", decode_type=\"multistart_sampling\", num_starts=100, select_best=True)\n",
    "        rewards.append(out[\"reward\"])\n",
    "\n",
    "    reward = torch.cat(rewards, dim=0).mean().item()\n",
    "    results[instance_type] = reward\n",
    "\n",
    "    print(\"Done evaluating instance type %s with reward %s\" % (instance_type, reward))\n",
    "\n",
    "    # avoid ooms due to cache not being cleared\n",
    "    model.rb.empty()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ],
   "id": "e8cc33f38bc48e7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wandb.finish()",
   "id": "85504c19a033507c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
