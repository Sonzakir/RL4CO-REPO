{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-24T23:17:39.688515Z",
     "start_time": "2024-12-24T23:17:33.553019Z"
    }
   },
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from rl4co.models.zoo.l2d.decoder import L2DDecoder\n",
    "from rl4co.models.zoo.matnet.matnet_w_sa import Encoder\n",
    "from rl4co.models.nn.env_embeddings.init import FJSPMatNetInitEmbedding\n",
    "import torch\n",
    "from rl4co.envs.scheduling.djssp.env import DJSSPEnv\n",
    "from rl4co.models import L2DPPOModel, L2DPolicy4PPO\n",
    "from rl4co.utils import RL4COTrainer\n",
    "from rl4co.models import StepwisePPO\n",
    "\n",
    "generator_params = {\n",
    "\"num_jobs\" : 8 ,\n",
    "\"num_machines\": 8 ,\n",
    "\"min_processing_time\": 1 ,\n",
    "\"max_processing_time\": 99 ,\n",
    "\"mtbf\":20 ,\n",
    "\"mttr\":4\n",
    "}\n",
    "env = DJSSPEnv(generator_params=generator_params,\n",
    "_torchrl_mode=True,\n",
    "stepwise_reward=True)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soner\\anaconda3\\envs\\reinforce\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T23:17:39.700658Z",
     "start_time": "2024-12-24T23:17:39.688515Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "5bea84ce740bc936",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Device Related Details",
   "id": "23ef7ff32677779d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if torch.cuda.is_available():\n",
    "    accelerator = \"gpu\"\n",
    "    batch_size = 32\n",
    "    train_data_size = 2_000\n",
    "    embed_dim = 128\n",
    "    num_encoder_layers = 4\n",
    "else:\n",
    "    accelerator = \"cpu\"\n",
    "    batch_size = 4\n",
    "    train_data_size = 1_000\n",
    "    embed_dim = 64\n",
    "    num_encoder_layers = 2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "id": "57201b8c1f6c8fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Policy = L2DPolicy4PPO",
   "id": "394363e0bf631c3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T23:17:40.038590Z",
     "start_time": "2024-12-24T23:17:39.883242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "init_embedding=FJSPMatNetInitEmbedding(embed_dim=256,scaling_factor=1000)\n",
    "feature_extractor =Encoder(embed_dim=256,init_embedding=init_embedding,num_heads=8,num_layers=4,normalization=\"batch\")\n",
    "decoder=L2DDecoder(env_name = env.name,embed_dim=256 ,het_emb=True,feature_extractor=feature_extractor)\n",
    "\n",
    "policy=L2DPolicy4PPO( env_name=env.name,decoder=decoder,embed_dim=256,scaling_factor=1000,het_emb=True)"
   ],
   "id": "74b63073f38249d5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soner\\anaconda3\\envs\\reinforce\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "C:\\Users\\soner\\anaconda3\\envs\\reinforce\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model = StepwisePPO",
   "id": "6e3b2777e3418cff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = StepwisePPO(env=env,policy=policy,  batch_size=128,val_batch_size=512,test_batch_size=64,mini_batch_size=512)\n",
   "id": "f51ece41e61289ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Scheduling of the untrained Model",
   "id": "40b419b8c1efc801"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "td = env.reset(batch_size=[1])",
   "id": "386e19a712e72443"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "policy = policy.to(device)\n",
    "out = model.policy.generate(td.clone(), env=env, phase=\"test\", decode_type=\"multistart_sampling\", num_starts=100, select_best=True)"
   ],
   "id": "b99fca4e641dc93c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Finishing Time",
   "id": "b573c669f0a0562"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "out[\"reward\"]",
   "id": "e2ca21486e1a8163"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training the Model",
   "id": "872d9892bd9bca51"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-24T23:17:40.054173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# max_epochs = 10\n",
    "trainer = RL4COTrainer(\n",
    "    max_epochs=1,\n",
    "    accelerator=accelerator,\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "\n",
    "trainer.fit(model)\n",
    "\n",
    "model = model.to(device)\n"
   ],
   "id": "5f809ef293206646",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\soner\\anaconda3\\envs\\reinforce\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Overriding gradient_clip_val to None for 'automatic_optimization=False' models\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Scheduling of the Trained Model",
   "id": "c745caec590b783"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "out = model.policy.generate(td.clone(), env=env, phase=\"test\", decode_type=\"multistart_sampling\", num_starts=100, select_best=True)",
   "id": "58d4d689288e4d03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exact finishing time",
   "id": "75367397cc1cf390"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "out[\"reward\"]\n",
   "id": "de2d2b0c8f1d9255"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test on Taillard Benchmark",
   "id": "bc9fe9068db0cbf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "! git clone https://github.com/tamy0612/JSPLIB.git",
   "id": "61530f0d11e37fcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def prepare_taillard_data(nj, nm):\n",
    "    # Target folder for Taillard instances\n",
    "    fp = f\"taillard/{nj}x{nm}\"\n",
    "\n",
    "    if not os.path.exists(fp):\n",
    "        os.makedirs(fp)\n",
    "\n",
    "    # Load the JSON file\n",
    "    with open('JSPLIB/instances.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Filter Taillard instances with matching jobs and machines\n",
    "    instances = [x for x in data if \"ta\" in x[\"name\"] and x[\"jobs\"] == nj and x[\"machines\"] == nm]\n",
    "    print(f\"Found {len(instances)} instances for {nj} jobs and {nm} machines\")\n",
    "\n",
    "    if not instances:\n",
    "        raise FileNotFoundError(f\"No matching Taillard instances found for {nj}x{nm}\")\n",
    "\n",
    "    # Copy files and validate\n",
    "    for instance in instances:\n",
    "        source_path = os.path.join(\"JSPLIB\", instance['path'])\n",
    "        target_path = os.path.join(fp, f\"{instance['name']}.txt\")\n",
    "\n",
    "        # Check if the source file exists\n",
    "        if os.path.exists(source_path):\n",
    "            print(f\"Copying {source_path} to {target_path}\")\n",
    "            os.system(f\"cp {source_path} {target_path}\")\n",
    "        else:\n",
    "            print(f\"Warning: Source file {source_path} does not exist\")\n",
    "\n",
    "    # Verify if files were copied\n",
    "    files_in_target = os.listdir(fp)\n",
    "    assert len(files_in_target) > 0, f\"No files copied to {fp}. Check source paths.\"\n",
    "    print(f\"Successfully prepared {len(files_in_target)} files in {fp}\")"
   ],
   "id": "75f3432bba5b1aa7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import gc\n",
    "\n",
    "device =  \"cpu\"\n",
    "\n",
    "# path to taillard instances\n",
    "FILE_PATH = \"taillard/{nj}x{nm}\"\n",
    "\n",
    "results = {}\n",
    "instance_types = [(15, 15), (20, 15), (20, 20), (30, 15), (30, 20)]\n",
    "\n",
    "for instance_type in instance_types:\n",
    "    print(\"------------\")\n",
    "    nj, nm = instance_type\n",
    "    prepare_taillard_data(nj, nm)\n",
    "    dataset = env.dataset(batch_size=[10], phase=\"test\", filename=FILE_PATH.format(nj=nj, nm=nm))\n",
    "    dl = DataLoader(dataset, batch_size=5, collate_fn=dataset.collate_fn)\n",
    "    rewards = []\n",
    "\n",
    "    for batch in dl:\n",
    "        td = env.reset(batch).to(device)\n",
    "        # use policy.generate to avoid grad calculations which can lead to oom\n",
    "        out = model.policy.generate(td, env=env, phase=\"test\", decode_type=\"multistart_sampling\", num_starts=100, select_best=True)\n",
    "        rewards.append(out[\"reward\"])\n",
    "\n",
    "    reward = torch.cat(rewards, dim=0).mean().item()\n",
    "    results[instance_type] = reward\n",
    "\n",
    "    print(\"Done evaluating instance type %s with reward %s\" % (instance_type, reward))\n",
    "\n",
    "    # avoid ooms due to cache not being cleared\n",
    "    model.rb.empty()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ],
   "id": "c9c155cb24a9360d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
