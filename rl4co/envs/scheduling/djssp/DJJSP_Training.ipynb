{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869a82d808105e98",
   "metadata": {},
   "source": "# DJSSP without training without JOB Interrupt"
  },
  {
   "cell_type": "code",
   "id": "6b1128afd232ef33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T19:41:32.620200Z",
     "start_time": "2024-12-13T19:41:30.030350Z"
    }
   },
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    accelerator = \"gpu\"\n",
    "    batch_size = 4\n",
    "    train_data_size = 2_000\n",
    "    embed_dim = 128\n",
    "    num_encoder_layers = 4\n",
    "else:\n",
    "    accelerator = \"cpu\"\n",
    "    batch_size = 3\n",
    "    train_data_size = 1_000\n",
    "    embed_dim = 64\n",
    "    num_encoder_layers = 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T19:41:43.905415Z",
     "start_time": "2024-12-13T19:41:38.810425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "from rl4co.envs.scheduling.djssp.env import DJSSPEnv\n",
    "from rl4co.models import L2DPolicy, L2DModel\n",
    "from rl4co.utils import RL4COTrainer\n",
    "import gc\n",
    "from rl4co.envs import JSSPEnv\n",
    "from rl4co.models.zoo.l2d.model import L2DPPOModel\n",
    "from rl4co.models.zoo.l2d.policy import L2DPolicy4PPO\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "generator_params = {\n",
    "\"num_jobs\" : 8 ,\n",
    "\"num_machines\": 8 ,\n",
    "\"min_processing_time\": 1 ,\n",
    "\"max_processing_time\": 99 ,\n",
    "\"mtbf\" : 17 ,\n",
    "\"mttr\" : 4\n",
    "}\n",
    "env = DJSSPEnv(generator_params=generator_params,\n",
    "_torchrl_mode=True,\n",
    "stepwise_reward=True)"
   ],
   "id": "c3bb28d2d1ba79f9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soner\\anaconda3\\envs\\env_24\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "77b88ae914f6245c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T19:41:47.737767Z",
     "start_time": "2024-12-13T19:41:46.061954Z"
    }
   },
   "source": [
    "# Policy: neural network, in this case with encoder-decoder architecture\n",
    "policy = L2DPolicy4PPO(\n",
    "    embed_dim=embed_dim,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    env_name=\"jssp\",\n",
    "    het_emb=False\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soner\\anaconda3\\envs\\env_24\\Lib\\site-packages\\executing\\executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "C:\\Users\\soner\\anaconda3\\envs\\env_24\\Lib\\ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Policy: neural network, in this case with encoder-decoder architecture\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m policy \u001B[38;5;241m=\u001B[39m L2DPolicy4PPO(\n\u001B[0;32m      3\u001B[0m     embed_dim\u001B[38;5;241m=\u001B[39membed_dim,\n\u001B[0;32m      4\u001B[0m     num_encoder_layers\u001B[38;5;241m=\u001B[39mnum_encoder_layers,\n\u001B[0;32m      5\u001B[0m     env_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjssp\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      6\u001B[0m     het_emb\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m      7\u001B[0m )\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\models\\zoo\\l2d\\policy.py:177\u001B[0m, in \u001B[0;36mL2DPolicy4PPO.__init__\u001B[1;34m(self, encoder, decoder, critic, embed_dim, num_encoder_layers, env_name, het_emb, scaling_factor, init_embedding, tanh_clipping, train_decode_type, val_decode_type, test_decode_type, **constructive_policy_kw)\u001B[0m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m init_embedding \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# TODO PPO specific init emb?\u001B[39;00m\n\u001B[1;32m--> 177\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    178\u001B[0m     encoder\u001B[38;5;241m=\u001B[39mencoder,\n\u001B[0;32m    179\u001B[0m     decoder\u001B[38;5;241m=\u001B[39mdecoder,\n\u001B[0;32m    180\u001B[0m     embed_dim\u001B[38;5;241m=\u001B[39membed_dim,\n\u001B[0;32m    181\u001B[0m     num_encoder_layers\u001B[38;5;241m=\u001B[39mnum_encoder_layers,\n\u001B[0;32m    182\u001B[0m     env_name\u001B[38;5;241m=\u001B[39menv_name,\n\u001B[0;32m    183\u001B[0m     het_emb\u001B[38;5;241m=\u001B[39mhet_emb,\n\u001B[0;32m    184\u001B[0m     scaling_factor\u001B[38;5;241m=\u001B[39mscaling_factor,\n\u001B[0;32m    185\u001B[0m     init_embedding\u001B[38;5;241m=\u001B[39minit_embedding,\n\u001B[0;32m    186\u001B[0m     stepwise_encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    187\u001B[0m     tanh_clipping\u001B[38;5;241m=\u001B[39mtanh_clipping,\n\u001B[0;32m    188\u001B[0m     train_decode_type\u001B[38;5;241m=\u001B[39mtrain_decode_type,\n\u001B[0;32m    189\u001B[0m     val_decode_type\u001B[38;5;241m=\u001B[39mval_decode_type,\n\u001B[0;32m    190\u001B[0m     test_decode_type\u001B[38;5;241m=\u001B[39mtest_decode_type,\n\u001B[0;32m    191\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconstructive_policy_kw,\n\u001B[0;32m    192\u001B[0m )\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m critic \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m env_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfjsp\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m het_emb:\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\models\\zoo\\l2d\\policy.py:72\u001B[0m, in \u001B[0;36mL2DPolicy.__init__\u001B[1;34m(self, encoder, decoder, embed_dim, num_encoder_layers, env_name, het_emb, scaling_factor, normalization, init_embedding, stepwise_encoding, tanh_clipping, train_decode_type, val_decode_type, test_decode_type, **constructive_policy_kw)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;66;03m# The decoder generates logits given the current td and heatmap\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m decoder \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 72\u001B[0m     decoder \u001B[38;5;241m=\u001B[39m L2DDecoder(\n\u001B[0;32m     73\u001B[0m         env_name\u001B[38;5;241m=\u001B[39menv_name,\n\u001B[0;32m     74\u001B[0m         embed_dim\u001B[38;5;241m=\u001B[39membed_dim,\n\u001B[0;32m     75\u001B[0m         actor_hidden_dim\u001B[38;5;241m=\u001B[39membed_dim,\n\u001B[0;32m     76\u001B[0m         num_encoder_layers\u001B[38;5;241m=\u001B[39mnum_encoder_layers,\n\u001B[0;32m     77\u001B[0m         init_embedding\u001B[38;5;241m=\u001B[39minit_embedding,\n\u001B[0;32m     78\u001B[0m         het_emb\u001B[38;5;241m=\u001B[39mhet_emb,\n\u001B[0;32m     79\u001B[0m         stepwise\u001B[38;5;241m=\u001B[39mstepwise_encoding,\n\u001B[0;32m     80\u001B[0m         scaling_factor\u001B[38;5;241m=\u001B[39mscaling_factor,\n\u001B[0;32m     81\u001B[0m         normalization\u001B[38;5;241m=\u001B[39mnormalization,\n\u001B[0;32m     82\u001B[0m     )\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m# Pass to constructive policy\u001B[39;00m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28msuper\u001B[39m(L2DPolicy, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m     86\u001B[0m     encoder\u001B[38;5;241m=\u001B[39mencoder,\n\u001B[0;32m     87\u001B[0m     decoder\u001B[38;5;241m=\u001B[39mdecoder,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconstructive_policy_kw,\n\u001B[0;32m     94\u001B[0m )\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\models\\zoo\\l2d\\decoder.py:199\u001B[0m, in \u001B[0;36mL2DDecoder.__init__\u001B[1;34m(self, env_name, feature_extractor, actor, init_embedding, embed_dim, actor_hidden_dim, actor_hidden_layers, num_encoder_layers, normalization, het_emb, stepwise, scaling_factor)\u001B[0m\n\u001B[0;32m    190\u001B[0m         feature_extractor \u001B[38;5;241m=\u001B[39m HetGNNEncoder(\n\u001B[0;32m    191\u001B[0m             env_name\u001B[38;5;241m=\u001B[39menv_name,\n\u001B[0;32m    192\u001B[0m             embed_dim\u001B[38;5;241m=\u001B[39membed_dim,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    196\u001B[0m             scaling_factor\u001B[38;5;241m=\u001B[39mscaling_factor,\n\u001B[0;32m    197\u001B[0m         )\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 199\u001B[0m         feature_extractor \u001B[38;5;241m=\u001B[39m GCN4JSSP(\n\u001B[0;32m    200\u001B[0m             embed_dim,\n\u001B[0;32m    201\u001B[0m             num_encoder_layers,\n\u001B[0;32m    202\u001B[0m             init_embedding\u001B[38;5;241m=\u001B[39minit_embedding,\n\u001B[0;32m    203\u001B[0m             scaling_factor\u001B[38;5;241m=\u001B[39mscaling_factor,\n\u001B[0;32m    204\u001B[0m         )\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_extractor \u001B[38;5;241m=\u001B[39m feature_extractor\n\u001B[0;32m    208\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m actor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\models\\zoo\\l2d\\encoder.py:20\u001B[0m, in \u001B[0;36mGCN4JSSP.__init__\u001B[1;34m(self, embed_dim, num_layers, init_embedding, **init_embedding_kwargs)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m init_embedding \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     18\u001B[0m     init_embedding \u001B[38;5;241m=\u001B[39m JSSPInitEmbedding(embed_dim, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minit_embedding_kwargs)\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m     21\u001B[0m     env_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjssp\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     22\u001B[0m     embed_dim\u001B[38;5;241m=\u001B[39membed_dim,\n\u001B[0;32m     23\u001B[0m     num_layers\u001B[38;5;241m=\u001B[39mnum_layers,\n\u001B[0;32m     24\u001B[0m     edge_idx_fn\u001B[38;5;241m=\u001B[39medge_idx_fn,\n\u001B[0;32m     25\u001B[0m     init_embedding\u001B[38;5;241m=\u001B[39minit_embedding,\n\u001B[0;32m     26\u001B[0m )\n",
      "File \u001B[1;32m~\\Desktop\\rl4co\\rl4co\\models\\nn\\graph\\gcn.py:72\u001B[0m, in \u001B[0;36mGCNEncoder.__init__\u001B[1;34m(self, env_name, embed_dim, num_layers, init_embedding, residual, edge_idx_fn, dropout, bias)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39medge_idx_fn \u001B[38;5;241m=\u001B[39m edge_idx_fn\n\u001B[0;32m     70\u001B[0m \u001B[38;5;66;03m# Define the GCN layers\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgcn_layers \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mModuleList(\n\u001B[1;32m---> 72\u001B[0m     [GCNConv(embed_dim, embed_dim, bias\u001B[38;5;241m=\u001B[39mbias) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_layers)]\n\u001B[0;32m     73\u001B[0m )\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "577050969bf7bda3",
   "metadata": {},
   "source": [
    "# default decoder\n",
    "policy.decoder"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6004906abcf8868",
   "metadata": {},
   "source": [
    "# default encoder\n",
    "policy.encoder"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "84d5590df1b23f13",
   "metadata": {},
   "source": [
    "# Visualize solution construction"
   ]
  },
  {
   "cell_type": "code",
   "id": "a72862a4bc412111",
   "metadata": {},
   "source": [
    "def make_step(td, decoder):\n",
    "    \"\"\"\n",
    "    Equivalent to FJSP make_step(), adapted for JSSP where no encoder is used.\n",
    "    td: TensorDict representing the current state of the environment.\n",
    "    decoder: The L2DDecoder or policy that generates action logits.\n",
    "    env: The JSSP environment instance.\n",
    "    \"\"\"\n",
    "    # Directly decode logits and mask from the raw input state `td`\n",
    "    hidden, _ = decoder.feature_extractor(td)\n",
    "\n",
    "    logits, mask = decoder(td, num_starts=0 , hidden = hidden)\n",
    "\n",
    "    # Mask invalid actions by setting their logits to -inf\n",
    "    action = logits.masked_fill(~mask, -torch.inf).argmax(1)\n",
    "\n",
    "    # Update the state with the selected action\n",
    "    td[\"action\"] = action\n",
    "\n",
    "    # Step the environment with the selected action\n",
    "    td = env.step(td)[\"next\"]\n",
    "\n",
    "    return td"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9c747b85da2bae6",
   "metadata": {},
   "source": [
    "td = env.reset(batch_size = batch_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "473a929582d913b0",
   "metadata": {},
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.display_functions import clear_output\n",
    "\n",
    "env.render(td, 0)\n",
    "# Update plot within a for loop\n",
    "while not td[\"done\"].all():\n",
    "    # Clear the previous output for the next iteration\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    td = make_step(td=td ,decoder = policy.decoder)\n",
    "    env.render(td, 0)\n",
    "    # Display updated plot\n",
    "    display(plt.gcf())\n",
    "\n",
    "    # Pause for a moment to see the changes\n",
    "    time.sleep(.4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9e486dbbab212769",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "id": "3c324a8bc18cfda1",
   "metadata": {},
   "source": [
    "# Policy: neural network, in this case with encoder-decoder architecture\n",
    "policy = L2DPolicy4PPO(\n",
    "    embed_dim=embed_dim,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    env_name=\"djssp\",\n",
    "    het_emb=False\n",
    ")\n",
    "\n",
    "model = L2DPPOModel(\n",
    "    env=env,\n",
    "    policy=policy,\n",
    "    batch_size=batch_size,\n",
    "    train_data_size=train_data_size,\n",
    "    val_data_size=1,\n",
    "    optimizer_kwargs={\"lr\": 1e-4}\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ebf4eed0-2c43-4a45-a9b2-458f8805ae02",
   "metadata": {},
   "source": [
    "td[\"time\"]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6e191d266d97c53",
   "metadata": {},
   "source": [
    "CHECKPOINT_PATH = \"last.ckpt\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "trainer = RL4COTrainer(\n",
    "    max_epochs=1,\n",
    "    accelerator=accelerator,\n",
    "    devices=1,\n",
    "    logger=None,\n",
    ")\n",
    "\n",
    "trainer.fit(model)\n",
    "\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1445823f-c1a8-4c91-9034-d4e12b35debf",
   "metadata": {},
   "source": [
    "\n",
    "generator_params = {\n",
    "\"num_jobs\" : 6 ,\n",
    "\"num_machines\": 10 ,\n",
    "\"min_processing_time\": 11 ,\n",
    "\"max_processing_time\": 230 ,\n",
    "\"mtbf\" : 8 ,\n",
    "\"mttr\" : 3\n",
    "}\n",
    "new_env  = DJSSPEnv(generator_params=generator_params)\n",
    " "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c13912a6-5bd9-4b5f-bf1b-1ce391878d4d",
   "metadata": {},
   "source": [
    "new_td = new_env.reset(batch_size = [2])\n",
    "out = model.policy.generate(new_td , env = new_env , phase =\"test\" ,decode_type=\"multistart_sampling\", num_starts=100, select_best=True)\n",
    "out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5c550aef-3593-4f3c-8d43-dfd1d16b368c",
   "metadata": {},
   "source": [
    "# Currently this part cannot be used since i dont have any FileGenerator \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5ea0aff4-3c9a-462e-80f7-cbbc3aa0c1b0",
   "metadata": {},
   "source": [
    "! git clone https://github.com/tamy0612/JSPLIB.git"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "96672a60-df9a-497e-8133-581a3d8bc7d9",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "def prepare_taillard_data(nj, nm):\n",
    "    fp = f\"taillard/{nj}x{nm}\"\n",
    "    if os.path.exists(fp):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(fp)\n",
    "        with open('../JSPLIB/instances.json', 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        instances = [x for x in data if \"ta\" in x[\"name\"] and x[\"jobs\"] == nj and x[\"machines\"] == nm]\n",
    "\n",
    "        for instance in instances:\n",
    "            os.popen(f\"cp JSPLIB/{instance['path']} {fp}/{instance['name']}.txt\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ccbe66a-7812-487b-8a28-a1665b80ba46",
   "metadata": {},
   "source": [
    "# path to taillard instances\n",
    "# FILE_PATH = \"taillard/{nj}x{nm}\"\n",
    "import gc\n",
    "from rl4co.envs import JSSPEnv\n",
    "from rl4co.models.zoo.l2d.model import L2DPPOModel\n",
    "from rl4co.models.zoo.l2d.policy import L2DPolicy4PPO\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os\n",
    "\n",
    "FILE_PATH = \"JSPLIB/taillard/{nj}x{nm}\"\n",
    "results = {}\n",
    "instance_types = [(15, 15), (20, 15), (20, 20), (30, 15), (30, 20)]\n",
    "\n",
    "for instance_type in instance_types:\n",
    "    nj, nm = instance_type\n",
    "    prepare_taillard_data(nj, nm)\n",
    "    dataset = env.dataset(batch_size=[3], phase=\"test\", filename=FILE_PATH.format(nj=nj, nm=nm))\n",
    "    print(dataset)\n",
    "    dl = DataLoader(dataset, batch_size=3, collate_fn=dataset.collate_fn)\n",
    "    rewards = []\n",
    "\n",
    "    for batch in dl:\n",
    "        td = env.reset(batch).to(device)\n",
    "        env.render(td,0)\n",
    "        # use policy.generate to avoid grad calculations which can lead to oom\n",
    "        out = model.policy.generate(td, env=env, phase=\"test\", decode_type=\"multistart_sampling\", num_starts=100, select_best=True)\n",
    "        rewards.append(out[\"reward\"])\n",
    "        \n",
    "        \n",
    "\n",
    "    reward = torch.cat(rewards, dim=0).mean().item()\n",
    "    results[instance_type] = reward\n",
    "\n",
    "    print(\"Done evaluating instance type %s with reward %s\" % (instance_type, reward))\n",
    "\n",
    "    # avoid ooms due to cache not being cleared\n",
    "    model.rb.empty()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4787a18e-81db-4d89-9b86-54c3f5fe6873",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
